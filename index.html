<!DOCTYPE html>
<html>
<head>
  <title>Text scoring and classification using edX EASE and Discern</title>
  <meta charset="utf-8">
  <meta name="description" content="Text scoring and classification using edX EASE and Discern">
  <meta name="author" content="Vik Paruchuri">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
    <link rel="stylesheet" href = "assets/css/assets.css">
<link rel="stylesheet" href = "assets/css/assets.css~">
<link rel="stylesheet" href = "assets/css/ribbons.css">

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
    <!-- END LOGO SLIDE -->
    

    <!-- TITLE SLIDE -->
    <!-- Should I move this to a Local Layout File? -->
    <slide class="title-slide segue nobackground">
      <hgroup class="auto-fadein">
        <h1>Text scoring and classification using edX EASE and Discern</h1>
        <h2></h2>
        <p>Vik Paruchuri<br/></p>
      </hgroup>
          </slide>

    <!-- SLIDES -->
      <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>What is edX?</h2>
  </hgroup>
  <article>
    <ul>
<li>edX (edx.org) is an educational non-profit created by founding partners Harvard and MIT in May of 2012.<br></li>
<li>Several other universities have since joined the effort.</li>
<li>Two major components:

<ul>
<li>edX platform learning management system (LMS)</li>
<li>edX studio content management system (CMS)</li>
<li>Together, enable authoring and delivery of courses at extremely large scale.</li>
</ul></li>
<li>Have hosted 30+ courses in subject areas from physics to justice, with a larger number upcoming.</li>
<li>Recenly passed the 1 million student mark.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Assessments on the edX platform</h2>
  </hgroup>
  <article>
    <ul>
<li>When edX launched, assessments were restricted to &quot;closed-choice&quot; response.</li>
<li><img src="assets/img/multiple_choice_problem.png" alt="multiple choice"></li>
<li><img src="assets/img/string_response.png" alt="string response"></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>How do we support humanities courses?</h2>
  </hgroup>
  <article>
    <ul>
<li>Difficult to support humanities courses without allowing students to enter free-text responses.

<ul>
<li>Richer assessments allow for varied instructional and learning styles.</li>
</ul></li>
<li>Short answer responses also useful for STEM courses offered by edX.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Potential strategies</h2>
  </hgroup>
  <article>
    <ul>
<li>Peer assessment (students grade each other)</li>
<li>Self assessment (students grade themselves)</li>
<li>Instructor assessment (instructor grades everyone)</li>
<li>AI Assessment (computer algorithm is trained and then grades students)</li>
<li>Scoring students based on participation and quality of discussions.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Overall Implementation</h2>
  </hgroup>
  <article>
    <ul>
<li>Through edx-ora (<a href="https://github.com/edx/edx-ora">https://github.com/edx/edx-ora</a>), implement a combination of peer assessment, self assessment, instructor assessment, and AI assessment.</li>
<li>edx-ora is currently being used to grade student free-text responses on the edX platform.</li>
<li>In alpha, and development is ongoing.</li>
<li>Although the focus of this talk is AI assessment, highly encourage looking at edX-ora if you are interested.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>How it looks</h2>
  </hgroup>
  <article>
    <ul>
<li><img src="assets/img/open_ended_response.png" alt="open response"></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>What is AI assessment, anyways?</h2>
  </hgroup>
  <article>
    <ul>
<li>AI assessment is the edX term for a more generic process: machine-learning based text classification and scoring.</li>
<li>We can start with any &quot;training set&quot; of text and associated scores.

<ul>
<li>ie Reddit posts and scores, essays and scores, books and the names of the authors who wrote them.</li>
</ul></li>
<li>The goal is to &quot;train&quot; a model that can map future input text to a score/category without being told what it is (prediction)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Training set example</h2>
  </hgroup>
  <article>
    <p>Let&#39;s say that I wanted to give a survey after the talks today and ask the following question:</p>

<p>Why do you want to learn about machine learning?</p>

<p>The responses might look like this:</p>

<pre><code>## 1 I like solving interesting problems.
## 2 What is machine learning?
## 3 I&#39;m not sure.
## 4 Machien lerning predicts eveyrthing.
</code></pre>

<p>Let&#39;s say that the survey also asks people to rate the talks on a scale of 0 to 2.</p>

<p>We would now have text and associated scores:</p>

<p><img src="figure/unnamed-chunk-3.png" alt="plot of chunk unnamed-chunk-3"> </p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>First steps</h2>
  </hgroup>
  <article>
    <ul>
<li>Computers can&#39;t directly understand text like humans can.

<ul>
<li>Humans automatically break down sentences into units of meaning.</li>
</ul></li>
<li>In this case, we have to first explicitly show the computer how to do this, in a process called tokenization.</li>
<li>After tokenization, we can convert the tokens into a matrix (bag of words model).</li>
<li>Once we have a matrix, we can use machine learning to train a model and predict scores.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Tokenization</h2>
  </hgroup>
  <article>
    <p>Let&#39;s tokenize the first survey response:</p>

<pre><code>## [1] &quot;I&quot;           &quot;like&quot;        &quot;solving&quot;     &quot;interesting&quot; &quot;problems&quot;
</code></pre>

<p>In this very simple case, we have just made each word a token (similar to <em>string.split(&#39; &#39;)</em>).</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Bag of words model</h2>
  </hgroup>
  <article>
    <ul>
<li>The bag of words model is a common way to represent documents in matrix form.</li>
<li>We construct an <em>nxt</em> document-term matrix, where <em>n</em> is the number of documents, and <em>t</em> is the number of unique terms.</li>
<li>Each column represents a unique term, and each cell <em>i,j</em>  represents how many of term <em>j</em> are in document <em>i</em>.</li>
</ul>

<p><img src="figure/unnamed-chunk-5.png" alt="plot of chunk unnamed-chunk-5"> </p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Bag of words overview</h2>
  </hgroup>
  <article>
    <ul>
<li>Ordering of words within a document is not taken into account in the basic bag of words model.</li>
<li>Once we have our document-term matrix, we can use machine learning techniques.</li>
<li>I have outlined a very simple framework, but it can easily be built on and extended.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Minimizing distances between vectors</h2>
  </hgroup>
  <article>
    <ul>
<li>We want to minimize the distance between two similar feature vectors.

<ul>
<li>For example, the below text fragments are substantially similar:</li>
<li>Bill wanted to grow up and be a Doctor.</li>
<li>bill wnted to gorw up and a be a doctor!</li>
<li>However, the simple tokenization we outlined above will not catch this.</li>
</ul></li>
<li>Spell correction using aspell or <a href="http://norvig.com/spell-correct.html">Peter Norvig&#39;s method</a>.</li>
<li>Lowercase input strings.</li>
<li>We minimize distance because we want the same response to get the same score.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Preserving information</h2>
  </hgroup>
  <article>
    <ul>
<li>It is important to preserve as much of the input information as we can.</li>
<li>When we start to spell correct or lowercase strings, we lose information.

<ul>
<li>We may be lowercasing the proper name Bill to the word bill.</li>
<li>If we are scoring an essay, and spelling is an important criteria, we don&#39;t want to lose that.</li>
</ul></li>
</ul>

<p>Old features:</p>

<p><img src="figure/unnamed-chunk-6.png" alt="plot of chunk unnamed-chunk-6"> </p>

<p>New features with lowercasing and spell correction:</p>

<p><img src="figure/unnamed-chunk-7.png" alt="plot of chunk unnamed-chunk-7"> </p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Orthogonality</h2>
  </hgroup>
  <article>
    <ul>
<li>As we saw in the slide before, we want to generate as much new information as possible while preserving existing information.</li>
<li>This will have us generate multiple <em>feature sets</em>.

<ul>
<li>Recommend having one feature set with original input text.</li>
</ul></li>
<li>Can measure orthoganality by taking vector distance or vector similarity between each document vector.

<ul>
<li>Need to reformat document vectors to contain all terms.</li>
</ul></li>
</ul>

<p>Cosine similarities:</p>

<pre><code>## [1] 1.0000 0.6667 1.0000 0.2500
</code></pre>

<p>Mean similarity:</p>

<pre><code>## [1] 0.7292
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Meta-features</h2>
  </hgroup>
  <article>
    <ul>
<li>We may also wish to extract higher-level features, such as number of spelling errors, number of grammar errors, etc.</li>
<li>Can add meta-features to the bag of words matrix.</li>
<li>Meta-features preserve information.

<ul>
<li>Can also extract and condense information.</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Which features are the right features?</h2>
  </hgroup>
  <article>
    <ul>
<li>Two simple ways

<ul>
<li>Create a machine learning model and measure error</li>
<li>Do a chi-squared test or a fisher test of significance.</li>
</ul></li>
<li>The tests essentially say &quot;Is feature x significantly different between low and high scoring texts&quot;?</li>
</ul>

<p><img src="figure/unnamed-chunk-10.png" alt="plot of chunk unnamed-chunk-10"> </p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Finally, some machine learning!</h2>
  </hgroup>
  <article>
    <ul>
<li>Now that we have generated our bag of words features and our meta-features, and figured out which ones are good, we can move onto machine learning.</li>
<li>The goal is to &quot;train&quot; a model that can predict future scores and categories.</li>
<li>Two broad categories of algorithms: classification and regression (not linear regression!)

<ul>
<li>Most regression assumes that you are on a continuous scale.</li>
<li>Classification is discrete.</li>
<li>Classification works best if you have less than 5 &quot;score points&quot; (we have 3).</li>
<li>Should try both, and measure error.</li>
</ul></li>
<li>We also have a lot of choice regarding the algorithm to use.

<ul>
<li>Random forest</li>
<li>Gradient boosted trees</li>
<li>Linear regression</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Linear regression</h2>
  </hgroup>
  <article>
    <ul>
<li>A simple linear equation is $y=m*x+b$ , where y is the target value(score), m is a coefficient, and b is a constant.</li>
<li>In linear regression, we would do something like $y=m&#95;{1}*x&#95;{1}+m&#95;{2}*x&#95;{2}+\dots+m&#95;{n}*x&#95;{n}+b$.

<ul>
<li>Each column in the matrix (feature) has a coefficient.</li>
<li>When we train the model, we calculate the coefficients.</li>
<li>Once we have the coefficients, we can predict how future text would score.</li>
</ul></li>
</ul>

<p>Coefficients:</p>

<pre><code>##              (Intercept) eveyrthing interesting learning
## coefficients           1         -1           1       -1
</code></pre>

<p>Words that are not shown do not have a coefficient (ie they did not have any useful information for scoring).</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Predicting scores</h2>
  </hgroup>
  <article>
    <ul>
<li>Now that we have our coefficients, and our intercept term, we can construct our equation and predict scores for new text.</li>
<li>Any new text has to go through the exact same process that we passed our training text through.

<ul>
<li>In this case, text will go through the bag of words model.  We will skip additional processing to keep it simple.</li>
</ul></li>
</ul>

<p>Let&#39;s use this as our &quot;test&quot; text that we will predict a score for:</p>

<pre><code>## 1 I want to learn to solve interesting problems.
</code></pre>

<p><img src="figure/unnamed-chunk-13.png" alt="plot of chunk unnamed-chunk-13"> </p>

<ul>
<li>Note that we have used the exact same features as in the training matrix. 

<ul>
<li>Without this, our model will not work.</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Predicting scores</h2>
  </hgroup>
  <article>
    <ul>
<li><p>We can use our new features to predict a score for our test text.</p></li>
<li><p>Our prediction is 2</p></li>
<li><p>We derive this by multiplying each column in the matrix by its associated coefficient, then adding those together and adding the intercept.</p></li>
<li><p>In this case, the intercept was 1 and the presence of the word <em>interesting</em> added another 1.</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Evaluating model accuracy</h2>
  </hgroup>
  <article>
    <ul>
<li>A very important question when creating a model and exploring various feature combinations is accuracy.</li>
<li>In order to measure accuracy, we use a principle called cross-validation.

<ul>
<li>Split training data set into n parts randomly.</li>
<li>Iterate from 1 to n and predict the scores of parts[n] from all the data in parts[!n].</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>

  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
<!-- Grab CDN jQuery, fall back to local if offline -->
<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
<script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery-1.7.min.js"><\/script>')</script>
<!-- Load Javascripts for Widgets -->
<!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script> -->
<script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
<script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- DONE LOADING HIGHLIGHTER JS FILES -->
</html>